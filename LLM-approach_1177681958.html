<!DOCTYPE html>
<html>
    <head>
        <title>AI Investigation : LLM approach</title>
        <link rel="stylesheet" href="styles/site.css" type="text/css" />
        <META http-equiv="Content-Type" content="text/html; charset=UTF-8">
    </head>

    <body class="theme-default aui-theme-default">
        <div id="page">
            <div id="main" class="aui-page-panel">
                <div id="main-header">
                    <div id="breadcrumb-section">
                        <ol id="breadcrumbs">
                            <li class="first">
                                <span><a href="index.html">AI Investigation</a></span>
                            </li>
                                                    <li>
                                <span><a href="AI-Investigation_934674757.html">AI Investigation</a></span>
                            </li>
                                                    <li>
                                <span><a href="S24-INDEX_1249640453.html">S24-INDEX</a></span>
                            </li>
                                                    <li>
                                <span><a href="Tech-Stack_1178992716.html">Tech Stack</a></span>
                            </li>
                                                </ol>
                    </div>
                    <h1 id="title-heading" class="pagetitle">
                                                <span id="title-text">
                            AI Investigation : LLM approach
                        </span>
                    </h1>
                </div>

                <div id="content" class="view">
                    <div class="page-metadata">
                            
        
    
        
    
        
        
            Created by <span class='author'> Jongeon</span> on Jun 19, 2024
                        </div>
                    <div id="main-content" class="wiki-content group">
                    <p>The best approach for leveraging a language model (LLM) as a learner, especially in an educational or enterprise setting, will involve balancing several factors: <strong>value, resources, performance, and specific needs</strong>.</p><p>Here’s a comparative analysis of three key approaches: using pre-trained models from open sources, fine-tuning existing architectures, and building a model from scratch</p><h2 id="LLMapproach-ComparativeAnalysis"><strong>Comparative Analysis</strong></h2><div class="table-wrap"><table data-table-width="760" data-layout="default" data-local-id="dc55236c-e091-4594-af1a-9952e4b35cbc" class="confluenceTable"><tbody><tr><td class="confluenceTd"><p style="text-align: center;"><strong>Approach</strong></p></td><td class="confluenceTd"><p style="text-align: center;"><strong>Description</strong></p></td><td class="confluenceTd"><p style="text-align: center;"><strong>Pros</strong></p></td><td class="confluenceTd"><p style="text-align: center;"><strong>Cons</strong></p></td><td class="confluenceTd"><p style="text-align: center;"><strong>Best Use Cases</strong></p></td></tr><tr><td class="confluenceTd"><p style="text-align: center;"><strong>Using Pre-Trained Models</strong></p></td><td class="confluenceTd"><p>Utilizing already trained models available from open-source platforms like Hugging Face without additional training or customization.</p></td><td class="confluenceTd"><p>Quick and easy to implement. Cost-effective Access to state-of-the-art models</p></td><td class="confluenceTd"><p>May not perfectly match specific use cases and Limited customization</p></td><td class="confluenceTd"><p>Rapid deployment of chatbots or NLP applications, Limited resources or budget, General-purpose applications</p></td></tr><tr><td class="confluenceTd"><p style="text-align: center;"><strong>Fine-Tuning Existing Architectures</strong></p></td><td class="confluenceTd"><p>Adapting pre-trained models like LLaMA 3, BERT, GPT-2 and Falcon to specific needs by further training them on a domain-specific dataset.</p></td><td class="confluenceTd"><p>Tailored to specific needs Utilizes pre-existing advanced models - Efficient</p></td><td class="confluenceTd"><p>Requires moderate resources and expertise. Fine-tuning can be complex and time-consuming</p></td><td class="confluenceTd"><p>Domain-specific applications, Organizations with moderate resources and expertise. Need for customized behavior and vocabulary</p></td></tr><tr><td class="confluenceTd"><p style="text-align: center;"><strong>Building from Scratch</strong></p></td><td class="confluenceTd"><p>Developing a new model architecture and training it from the ground up using a large dataset.</p></td><td class="confluenceTd"><p>Fully customized solution - Optimal performance for the specific task, Full control</p></td><td class="confluenceTd"><p>Extremely resource-intensive, requires deep expertise, long development timeline</p></td><td class="confluenceTd"><p>Niche or highly specialized applications - Organizations with significant resources and expertise, Projects where existing models are inadequate</p></td></tr></tbody></table></div><p /><h2 id="LLMapproach-DetailedComparison"><strong>Detailed Comparison</strong></h2><p /><ol start="1"><li><p><strong>Using Pre-Trained Models from Open Sources</strong></p></li></ol><p><strong>Overview</strong></p><p>Pre-trained models are ready-to-use models available from platforms like Hugging Face. They are trained on diverse datasets and can be directly deployed or slightly adapted using configuration adjustments.</p><div class="table-wrap"><table data-table-width="760" data-layout="default" data-local-id="035bdd91-6c76-44c3-b299-240ee238f928" class="confluenceTable"><colgroup><col style="width: 127.0px;"/><col style="width: 632.0px;"/></colgroup><tbody><tr><th data-highlight-colour="#deebff" rowspan="3" class="confluenceTh"><p style="text-align: center;"><strong>Pros</strong></p></th><td data-highlight-colour="#deebff" class="confluenceTd"><ul><li><p><strong>Speed and Ease of Deployment</strong>: Pre-trained models can be used out-of-the-box, allowing for rapid deployment without the need for extensive training or customization.</p></li></ul></td></tr><tr><td data-highlight-colour="#deebff" class="confluenceTd"><ul><li><p><strong>Cost-Effective</strong>: Saves the computational and financial resources required for training large models. Many high-quality models are freely available.</p></li></ul></td></tr><tr><td data-highlight-colour="#deebff" class="confluenceTd"><ul><li><p><strong>Access to Advanced Capabilities</strong>: Provides access to state-of-the-art models like GPT-3, BERT, or Falcon without the need for in-house development.</p></li></ul></td></tr><tr><th data-highlight-colour="#ffebe6" rowspan="2" class="confluenceTh"><p style="text-align: center;"><strong>Cons</strong></p></th><td data-highlight-colour="#ffebe6" class="confluenceTd"><ul><li><p><strong>Limited Customization</strong>: Pre-trained models may not perfectly align with specific needs, especially if the application requires specialized vocabulary or behavior.</p></li></ul></td></tr><tr><td data-highlight-colour="#ffebe6" class="confluenceTd"><ul><li><p><strong>Performance Constraints</strong>: While they are versatile, these models might not deliver optimal performance for niche or highly specialized tasks.</p></li></ul></td></tr><tr><th data-highlight-colour="#e3fcef" rowspan="3" class="confluenceTh"><p style="text-align: center;"><strong>Best Use Cases</strong></p></th><td data-highlight-colour="#e3fcef" class="confluenceTd"><ul><li><p><strong>General-Purpose Applications</strong>: Ideal for applications where the task is broadly covered by the model’s training, such as general chatbots, translation, or summarization.</p></li></ul></td></tr><tr><td data-highlight-colour="#e3fcef" class="confluenceTd"><ul><li><p><strong>Rapid Prototyping</strong>: Suitable for projects needing quick turnaround with minimal customization.</p></li></ul></td></tr><tr><td data-highlight-colour="#e3fcef" class="confluenceTd"><ul><li><p><strong>Budget-Constrained Projects</strong>: Perfect for projects with limited resources that cannot afford the cost of training large models.</p></li></ul></td></tr></tbody></table></div><p> </p><ol start="2"><li><p><strong>Fine-Tuning Existing Architectures</strong></p></li></ol><p><strong>Overview</strong></p><p>Fine-tuning involves taking an existing pre-trained model and adapting it to a specific task by training it further on a domain-specific dataset. This approach uses models like LLaMA 3, GPT-2, BERT, or Falcon as the starting point. </p><div class="table-wrap"><table data-table-width="760" data-layout="default" data-local-id="ae82db11-95c9-4d74-bf69-851a2ffef9d7" class="confluenceTable"><colgroup><col style="width: 127.0px;"/><col style="width: 632.0px;"/></colgroup><tbody><tr><th data-highlight-colour="#deebff" rowspan="3" class="confluenceTh"><p style="text-align: center;"><strong>Pros</strong></p></th><td data-highlight-colour="#deebff" class="confluenceTd"><ul><li><p><strong>Task-Specific Adaptation</strong>: Allows the model to learn the nuances of the specific application domain, improving performance on specialized tasks.</p></li></ul></td></tr><tr><td data-highlight-colour="#deebff" class="confluenceTd"><ul><li><p><strong>Leveraging Pre-Trained Knowledge</strong>: Benefits from the extensive training already performed on the base model, saving significant resources compared to training from scratch.</p></li></ul></td></tr><tr><td data-highlight-colour="#deebff" class="confluenceTd"><ul><li><p><strong>Balance of Performance and Resources</strong>: Offers a good balance between achieving high performance and managing resource costs.</p></li></ul></td></tr><tr><th data-highlight-colour="#ffebe6" rowspan="2" class="confluenceTh"><p style="text-align: center;"><strong>Cons</strong></p></th><td data-highlight-colour="#ffebe6" class="confluenceTd"><ul><li><p><strong>Moderate Resource and Expertise Requirements</strong>: While not as demanding as training from scratch, fine-tuning still requires computational power and expertise in machine learning and NLP.</p></li></ul></td></tr><tr><td data-highlight-colour="#ffebe6" class="confluenceTd"><ul><li><p><strong>Time-Consuming</strong>: The process can be time-consuming, especially if the domain-specific data is large or the task complexity is high.</p></li></ul></td></tr><tr><th data-highlight-colour="#e3fcef" rowspan="3" class="confluenceTh"><p style="text-align: center;"><strong>Best Use Cases</strong></p></th><td data-highlight-colour="#e3fcef" class="confluenceTd"><ul><li><p><strong>Domain-Specific Applications</strong>: Ideal for tasks requiring a model to understand and generate content specific to a particular domain or industry.</p></li></ul></td></tr><tr><td data-highlight-colour="#e3fcef" class="confluenceTd"><ul><li><p><strong>Moderate Resources and Expertise</strong>: Suitable for organizations that can afford moderate computational and financial investments and have access to ML expertise.</p></li></ul></td></tr><tr><td data-highlight-colour="#e3fcef" class="confluenceTd"><ul><li><p><strong>Enhanced Customization</strong>: Useful for applications where a high degree of customization is needed, such as legal or medical text processing.</p></li></ul></td></tr></tbody></table></div><p> </p><ol start="3"><li><p><strong>Building from Scratch</strong></p></li></ol><p><strong>Overview</strong></p><p>This approach involves designing a new model architecture and training it from the ground up using large datasets. This is typically undertaken when existing models do not meet specific needs or constraints.</p><div class="table-wrap"><table data-table-width="760" data-layout="default" data-local-id="98443ee1-62ab-4845-bfbd-09eae60e719c" class="confluenceTable"><colgroup><col style="width: 127.0px;"/><col style="width: 632.0px;"/></colgroup><tbody><tr><th data-highlight-colour="#deebff" rowspan="3" class="confluenceTh"><p style="text-align: center;"><strong>Pros</strong></p></th><td data-highlight-colour="#deebff" class="confluenceTd"><ul><li><p><strong>Complete Customization</strong>: Allows full control over the model’s architecture, training process, and behavior, enabling precise alignment with specific requirements.</p></li></ul></td></tr><tr><td data-highlight-colour="#deebff" class="confluenceTd"><ul><li><p><strong>Optimal Performance</strong>: Can achieve the highest performance for specialized tasks or unique constraints.</p></li></ul></td></tr><tr><td data-highlight-colour="#deebff" class="confluenceTd"><ul><li><p><strong>Innovation Potential</strong>: Provides opportunities to develop new model architectures and explore novel techniques.</p></li></ul></td></tr><tr><th data-highlight-colour="#ffebe6" rowspan="3" class="confluenceTh"><p style="text-align: center;"><strong>Cons</strong></p></th><td data-highlight-colour="#ffebe6" class="confluenceTd"><ul><li><p><strong>Extremely Resource-Intensive</strong>: Requires significant computational resources, financial investment, and time to train large models from scratch.</p></li></ul></td></tr><tr><td data-highlight-colour="#ffebe6" class="confluenceTd"><ul><li><p><strong>High Expertise Requirement</strong>: Demands a deep understanding of machine learning, NLP, and model architecture design.</p></li></ul></td></tr><tr><td data-highlight-colour="#ffebe6" class="confluenceTd"><ul><li><p><strong>Long Development Timeline</strong>: Developing and training a new model can take a substantial amount of time, often months or even years.</p></li></ul></td></tr><tr><th data-highlight-colour="#e3fcef" rowspan="3" class="confluenceTh"><p style="text-align: center;"><strong>Best Use Cases</strong></p></th><td data-highlight-colour="#e3fcef" class="confluenceTd"><ul><li><p><strong>Highly Specialized Applications</strong>: Necessary for tasks that existing models cannot adequately address, such as niche scientific research or proprietary business processes.</p></li></ul></td></tr><tr><td data-highlight-colour="#e3fcef" class="confluenceTd"><ul><li><p><strong>Organizations with Significant Resources</strong>: Suitable for large organizations or projects with the necessary financial and technical resources.</p></li></ul></td></tr><tr><td data-highlight-colour="#e3fcef" class="confluenceTd"><ul><li><p><strong>R&amp;D and Innovation</strong>: Ideal for research and development projects aiming to push the boundaries of current technology.</p></li></ul></td></tr></tbody></table></div><h2 id="LLMapproach-SummaryandRecommendations"><strong><u>Summary and Recommendations</u></strong></h2><p><strong>Value as a Learner</strong>: For educational or enterprise applications, <strong>fine-tuning existing architectures</strong> strikes the best balance between performance, resource investment, and customization. It allows for leveraging the power of advanced pre-trained models while tailoring them to specific needs without the extreme costs and complexities of building from scratch.</p><p><strong>Using Pre-Trained Models</strong>: This is highly beneficial for quick deployment and cost-effective solutions, especially if the task does not require deep customization.</p><p><strong>Building from Scratch</strong>: This is generally only recommended for highly specialized use cases or when existing models are inadequate. It involves substantial investment and expertise, suitable for large-scale or cutting-edge research projects.</p><p><strong> </strong></p><p><strong><u>Conclusion</u></strong></p><p>For most use cases in education or enterprise environments, fine-tuning pre-trained models like <strong>LLaMA 3, BERT, GPT-2, or Falcon</strong> offers the best combination of performance, flexibility, and resource management. This approach allows for adapting cutting-edge AI to meet specific needs without the extensive costs and challenges of training from scratch.</p>
                    </div>

                    
                                                      
                </div>             </div> 
            <div id="footer" role="contentinfo">
                <section class="footer-body">
                    <p>Document generated by Confluence on May 16, 2025 14:25</p>
                    <div id="footer-logo"><a href="http://www.atlassian.com/">Atlassian</a></div>
                </section>
            </div>
        </div>     </body>
</html>
