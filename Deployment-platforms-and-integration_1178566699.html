<!DOCTYPE html>
<html>
    <head>
        <title>AI Investigation : Deployment platforms and integration</title>
        <link rel="stylesheet" href="styles/site.css" type="text/css" />
        <META http-equiv="Content-Type" content="text/html; charset=UTF-8">
    </head>

    <body class="theme-default aui-theme-default">
        <div id="page">
            <div id="main" class="aui-page-panel">
                <div id="main-header">
                    <div id="breadcrumb-section">
                        <ol id="breadcrumbs">
                            <li class="first">
                                <span><a href="index.html">AI Investigation</a></span>
                            </li>
                                                    <li>
                                <span><a href="AI-Investigation_934674757.html">AI Investigation</a></span>
                            </li>
                                                    <li>
                                <span><a href="S24-INDEX_1249640453.html">S24-INDEX</a></span>
                            </li>
                                                    <li>
                                <span><a href="Tech-Stack_1178992716.html">Tech Stack</a></span>
                            </li>
                                                </ol>
                    </div>
                    <h1 id="title-heading" class="pagetitle">
                                                <span id="title-text">
                            AI Investigation : Deployment platforms and integration
                        </span>
                    </h1>
                </div>

                <div id="content" class="view">
                    <div class="page-metadata">
                            
        
    
        
    
        
        
            Created by <span class='author'> Diego Andres Bolanos Osejo (Unlicensed)</span>, last modified on Jun 20, 2024
                        </div>
                    <div id="main-content" class="wiki-content group">
                    <h2 id="Deploymentplatformsandintegration-CommunityCloudforAppDeployment">Community Cloud for App Deployment</h2><p>Community clouds offer a collaborative environment for deploying, managing, and maintaining applications directly from GitHub Repositories by picking up a repo, branch, or file or using a prebuilt app template.</p><h3 id="Deploymentplatformsandintegration-KeyFeaturesandBenefits:"><strong>Key Features and Benefits:</strong></h3><ul><li><p><strong>Deploy in one click</strong></p><ul><li><p>Your fully hosted app is ready to share in under a minute.</p></li></ul></li><li><p><strong>Keep your code in your repo</strong></p><ul><li><p>No changes to your development process. Code stays on GitHub.</p></li></ul></li><li><p><strong>Live updates</strong></p><ul><li><p>Your apps update instantly when you push code changes.</p></li></ul></li><li><p><strong>Securely connect to data</strong></p><ul><li><p>Connect to all your data sources using secure protocols.</p></li></ul></li><li><p><strong>Restrict access to apps</strong></p><ul><li><p>Authenticate viewers with per-app viewer allow-lists.</p></li></ul></li><li><p><strong>Easily manage your apps</strong></p><ul><li><p>View, collaborate, and manage all your apps in a single place.</p></li></ul></li></ul><h3 id="Deploymentplatformsandintegration-Limitations"><strong>Limitations</strong></h3><p>Streamlit community cloud comes with the following limits</p><h3 id="Deploymentplatformsandintegration-Resourcesperapp"><strong>Resources per app</strong></h3><p><strong>1 GB Resource Limit:</strong></p><ul><li><p>Each app deployed on Streamlit Community Cloud is allocated a maximum of 1 GB of resources. This includes memory (RAM) and storage used by the app during its runtime. This limitation ensures that individual apps do not consume excessive resources, which could affect the platform's performance for other users.</p></li></ul><p><strong>Private apps</strong></p><p><strong>1 Private App Limit:</strong></p><ul><li><p>Users can deploy one private app on Streamlit Community Cloud. A private app is accessible only to users who have been granted explicit access. This feature is useful for sharing apps within a small group or for internal testing before making an app public. The restriction to a single private app encourages users to manage their private resources judiciously and consider upgrading to a professional plan if more private apps are required.</p></li></ul><p><strong>Public apps</strong></p><p><strong>Unlimited Public Apps:</strong></p><ul><li><p>Users can deploy an unlimited number of public apps. Public apps are accessible to anyone with the link, making them ideal for sharing with a wider audience or for demonstrating projects to the community. This unlimited deployment capacity for public apps allows users to experiment, iterate, and share their work without worrying about hitting a limit.</p></li></ul><h2 id="Deploymentplatformsandintegration-End-to-endDeploymentWorkflow">End-to-end Deployment Workflow</h2><p>This workflow focuses on deploying a conversational AI application using NLUX, emphasizing cost efficiency by effectively leveraging microservices and cloud resources.</p><p>This process involves creating a specific environment with the technologies needed, for example:</p><h2 id="Deploymentplatformsandintegration-UsingNLUX">Using NLUX</h2><h3 id="Deploymentplatformsandintegration-NLUXWithNext.jsAndVercelAI">NLUX With Next.js And Vercel AI</h3><ul><li><p>Next.js is the most popular React framework for building web applications. Combined with Vercel AI SDK and NLUX, it provides a perfect combination for building AI assistants for your web application.</p></li></ul><h3 id="Deploymentplatformsandintegration-NLUXAndLangChainLangServe">NLUX And LangChain LangServe</h3><ul><li><p>LangChain is popular framework for building services and backends powered by LLMs. It offers a library called LangSmith that exposes a REST API for interfacing with LLMs.</p></li></ul><h3 id="Deploymentplatformsandintegration-NLUXAndChatGPTviaNode.js">NLUX And ChatGPT via Node.js</h3><ul><li><p>Integrate the OpenAI ChatGPT model with the <em>NLUX</em> library using Node.js.</p></li></ul><ol start="1"><li><p>Create an Express.js server that connects to the OpenAI API</p></li><li><p>Create an AI chat component using <em>NLUX</em> and connect it to the Express.js server</p></li><li><p>Use <a class="external-link" href="https://www.npmjs.com/package/@nlbridge/express" rel="nofollow">nlbridge</a> to create the server endpoint that bridges the OpenAI API with the <em>NLUX</em> library.<br/><em>nlbridge</em> is a middleware library created by the <em>NLUX</em> team to simplify the integration of LLMs with web applications.</p></li></ol><p><a class="external-link" data-card-appearance="inline" href="https://docs.nlkit.com/nlux/learn/get-started/" rel="nofollow">https://docs.nlkit.com/nlux/learn/get-started/</a> </p><h2 id="Deploymentplatformsandintegration-WebFrameworkImplementation">Web Framework Implementation</h2><h3 id="Deploymentplatformsandintegration-AngularAndLangChainLangServe">Angular And LangChain LangServe</h3><ul><li><p>LangChain is popular framework for building services and backends powered by LLMs. It offers a library called LangSmith that exposes a REST API for interfacing with LLMs.</p></li></ul><h3 id="Deploymentplatformsandintegration-AngularAndOpenAIviaNestJS">Angular And OpenAI via NestJS</h3><ul><li><p>Integrate the OpenAI ChatGPT model using NestJS</p></li></ul><ol start="1"><li><p>Create a NestJS server that connects to the OpenAI API</p></li><li><p>Create an AI chat component using TailwindCss and connect it to the NestJS server</p></li><li><p>Use RestAPI endpoint to retreive the data and integrate the LLM to the web application.</p></li></ol><h3 id="Deploymentplatformsandintegration-ImplementingMicroservicesforBackendLogic">Implementing Microservices for Backend Logic</h3><h4 id="Deploymentplatformsandintegration-SettingUpaMicroservicesArchitecture:"><strong>Setting Up a Microservices Architecture:</strong></h4><ul><li><p><strong>Authentication Service:</strong></p><ul><li><p><strong>Purpose:</strong> Handle user authentication and authorization.</p></li><li><p><strong>Responsibilities:</strong> Verify user credentials, issue tokens, and manage user sessions.</p></li><li><p><strong>Technologies:</strong> Express.js, JWT (JSON Web Token), OAuth2.</p></li></ul></li><li><p><strong>Chatbot Service:</strong></p><ul><li><p><strong>Purpose:</strong> Handle AI chatbot interactions.</p></li><li><p><strong>Responsibilities:</strong> Process user queries, generate responses using LangChain, manage conversation history.</p></li><li><p><strong>Technologies:</strong> LangChain, OpenAI API, Express.js.</p></li></ul></li><li><p><strong>Media Processing Service:</strong></p><ul><li><p><strong>Purpose:</strong> Handle the ingestion, processing, and storage of various media types.</p></li><li><p><strong>Responsibilities:</strong></p><ul><li><p><strong>Audio/Video Processing:</strong> Transcode, compress, and store audio/video files.</p></li><li><p><strong>Document Processing:</strong> Convert and store documents (PDF, DOCX, PPT).</p></li><li><p><strong>Link Management:</strong> Fetch metadata, generate previews.</p></li></ul></li><li><p><strong>Technologies:</strong> FFmpeg (for audio/video), Tika/LibreOffice (for documents), Node.js.</p></li></ul></li><li><p><strong>D2L Integration Service:</strong></p><ul><li><p><strong>Purpose:</strong> Interface with D2L APIs to fetch and manage course-related data.</p></li><li><p><strong>Responsibilities:</strong> Fetch course content, manage assignments and grades, sync with D2L platform.</p></li><li><p><strong>Technologies:</strong> D2L Brightspace API, Node.js.</p></li></ul></li><li><p><strong>Notification Service:</strong></p><ul><li><p><strong>Purpose:</strong> Manage notifications and alerts for users.</p></li><li><p><strong>Responsibilities:</strong> Send email/SMS notifications, manage in-app notifications.</p></li><li><p><strong>Technologies:</strong> Node.js, SendGrid/Twilio.</p></li></ul></li><li><p><strong>Storage Service:</strong></p><ul><li><p><strong>Purpose:</strong> Handle storage and retrieval of media files and data.</p></li><li><p><strong>Responsibilities:</strong> Manage cloud storage (AWS S3, Google Cloud Storage), database interactions.</p></li><li><p><strong>Technologies:</strong> AWS S3/Google Cloud Storage, MongoDB/PostgreSQL.</p></li></ul></li></ul><p /><h3 id="Deploymentplatformsandintegration-Cloudprovider(AWS,GoogleCloud,Azure)">Cloud provider (AWS, Google Cloud, Azure)</h3><ul><li><p><strong>AWS:</strong> Use ECS or EKS for deploying the Docker containers.</p></li><li><p><strong>Google Cloud:</strong> Use Google Kubernetes Engine (GKE) or Cloud Run.</p></li><li><p><strong>Azure:</strong> Use Azure Kubernetes Service (AKS) or Azure App Service.</p></li></ul><h4 id="Deploymentplatformsandintegration-MonitoringandCostManagement"><strong>Monitoring and Cost Management</strong></h4><h4 id="Deploymentplatformsandintegration-Monitoring:"><strong>Monitoring:</strong></h4><ul><li><p>Use cloud provider tools (e.g., AWS CloudWatch, Google Stackdriver) to monitor resource usage and performance.</p></li></ul><p><strong>Cost Management:</strong></p><ul><li><p>Regularly review resource usage and optimize services to reduce costs.</p></li><li><p>Scale services dynamically based on demand to avoid over-provisioning.</p></li></ul>
                    </div>

                    
                                                      
                </div>             </div> 
            <div id="footer" role="contentinfo">
                <section class="footer-body">
                    <p>Document generated by Confluence on May 16, 2025 14:25</p>
                    <div id="footer-logo"><a href="http://www.atlassian.com/">Atlassian</a></div>
                </section>
            </div>
        </div>     </body>
</html>
