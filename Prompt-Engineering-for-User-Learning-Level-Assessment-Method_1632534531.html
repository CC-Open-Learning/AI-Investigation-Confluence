<!DOCTYPE html>
<html>
    <head>
        <title>AI Investigation : Prompt Engineering for User Learning Level Assessment Method</title>
        <link rel="stylesheet" href="styles/site.css" type="text/css" />
        <META http-equiv="Content-Type" content="text/html; charset=UTF-8">
    </head>

    <body class="theme-default aui-theme-default">
        <div id="page">
            <div id="main" class="aui-page-panel">
                <div id="main-header">
                    <div id="breadcrumb-section">
                        <ol id="breadcrumbs">
                            <li class="first">
                                <span><a href="index.html">AI Investigation</a></span>
                            </li>
                                                    <li>
                                <span><a href="AI-Investigation_934674757.html">AI Investigation</a></span>
                            </li>
                                                    <li>
                                <span><a href="W25-INDEX_1551106050.html">W25-INDEX</a></span>
                            </li>
                                                    <li>
                                <span><a href="Tech-Research_1583087617.html">Tech Research</a></span>
                            </li>
                                                </ol>
                    </div>
                    <h1 id="title-heading" class="pagetitle">
                                                <span id="title-text">
                            AI Investigation : Prompt Engineering for User Learning Level Assessment Method
                        </span>
                    </h1>
                </div>

                <div id="content" class="view">
                    <div class="page-metadata">
                            
        
    
        
    
        
        
            Created by <span class='author'> Jongeon</span> on Feb 19, 2025
                        </div>
                    <div id="main-content" class="wiki-content group">
                    <p><style>[data-colorid=nppygmxkqh]{color:#0747a6} html[data-color-mode=dark] [data-colorid=nppygmxkqh]{color:#5999f8}[data-colorid=ekxjfa5xbl]{color:#0747a6} html[data-color-mode=dark] [data-colorid=ekxjfa5xbl]{color:#5999f8}[data-colorid=p5q4dagpmk]{color:#0747a6} html[data-color-mode=dark] [data-colorid=p5q4dagpmk]{color:#5999f8}[data-colorid=uf886b6dgx]{color:#0747a6} html[data-color-mode=dark] [data-colorid=uf886b6dgx]{color:#5999f8}</style>AI prompt engineering is the practice of designing effective prompts to optimize AI responses and performance.</p><p>In the DTA project, prompt engineering was used to understand user intent, assess learning levels, and provide tailored curricula. This post focuses specifically on user levelling prompts, which are designed to accurately measure how much knowledge a user has on a given subject. By leveraging prompt engineering, the AI evaluates user proficiency and determines their level effectively.</p><p /><ul><li><p><strong>Optimal Prompt Engineering Techniques for Digital Teaching Assistant Level Assessment</strong></p><ul><li><p>Generating questions that are clearly differentiated by level</p></li><li><p>Ensuring AI evaluates user responses consistently and objectively</p></li><li><p>Assigning the same level when users provide similar answers</p></li></ul></li></ul><p /><h2 id="PromptEngineeringforUserLearningLevelAssessmentMethod-1.AssessmentQuestionGeneration"><strong>1. Assessment Question Generation</strong></h2><h3 id="PromptEngineeringforUserLearningLevelAssessmentMethod-InstructionPrompting(ProvidingClearGuidelines)"><strong><span data-colorid="p5q4dagpmk">Instruction Prompting</span>(Providing Clear Guidelines)</strong></h3><p>This technique guides AI in generating questions by following clear principles and criteria.</p><ul><li><p>Categorize question difficulty into <strong>beginner, intermediate, and advanced</strong> levels.</p></li><li><p>Generate questions based on evaluation rubrics (e.g., <strong>Bloom's Taxonomy</strong>).</p></li></ul><p>ðŸ”¹ Example:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Confluence" data-theme="Confluence">Generate five questions to assess Python programming skills.  
- Each question should correspond to one of the three levels: beginner, intermediate, or advanced.  
- Follow Bloom&rsquo;s Taxonomy to progressively increase difficulty.  
- Ensure the questions are clear and unambiguous.  
- Provide example answers for each question.  </pre>
</div></div><p /><h2 id="PromptEngineeringforUserLearningLevelAssessmentMethod-2.UserResponseEvaluationandLevelAssessment">2. <strong>User Response Evaluation and Level Assessment</strong></h2><h3 id="PromptEngineeringforUserLearningLevelAssessmentMethod-Self-ConsistencyPrompting(EnsuringConsistency)"><strong><span data-colorid="nppygmxkqh">Self-Consistency Prompting</span>(Ensuring Consistency)</strong></h3><p>This method allows AI to <strong>evaluate the same response multiple times and select the most consistent result</strong>.</p><ul><li><p>AI <strong>evaluates the same response multiple times</strong> and selects the most frequently occurring result.</p></li><li><p>Prevents AI from generating different responses each time.</p></li></ul><p>ðŸ”¹ Example:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Confluence" data-theme="Confluence">Evaluate the following user response.  
- Perform the same evaluation five times.  
- Select the most consistent level among the results.  
- Evaluation criteria: logical reasoning, conceptual accuracy, and application ability.  </pre>
</div></div><p /><h3 id="PromptEngineeringforUserLearningLevelAssessmentMethod-Chain-of-Thought(CoT)Prompting(ApplyingLogicalReasoning)"><strong><span data-colorid="ekxjfa5xbl">Chain-of-Thought (CoT) Prompting</span> (Applying Logical Reasoning)</strong></h3><p>This technique encourages AI to <strong>analyze user responses step by step</strong>.</p><ul><li><p><strong>Instead of determining the level in one step, AI follows an analysis process before making a final assessment</strong>.</p></li><li><p>The evaluation process becomes more transparent, and AI can justify its reasoning.</p></li></ul><p>ðŸ”¹ Example:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Confluence" data-theme="Confluence">Analyze the user response to determine the appropriate level.  
Step 1: Identify key concepts in the response.  
Step 2: Compare the identified concepts with the evaluation rubric.  
Step 3: Assess logical flow and depth of reasoning.  
Step 4: Select the appropriate level (beginner, intermediate, or advanced).  
Step 5: Explain the reasoning behind the selected level.  </pre>
</div></div><p /><h3 id="PromptEngineeringforUserLearningLevelAssessmentMethod-Few-ShotPrompting(ProvidingExamplesforEvaluationGuidance)"><strong><span data-colorid="uf886b6dgx">Few-Shot Prompting</span> (Providing Examples for Evaluation Guidance)</strong></h3><p>This technique provides AI with <strong>predefined examples for each level</strong> to guide the evaluation process.</p><ul><li><p>AI compares user responses with predefined examples to determine the appropriate level.</p></li><li><p><strong>Ensures consistency and improves reliability</strong> in assessments.</p></li></ul><p>ðŸ”¹ Example:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Confluence" data-theme="Confluence">Here are examples of programming knowledge evaluations.  

Example 1 (Beginner):  
- User: &quot;Python is a programming language used for web development.&quot;  
- AI Evaluation: Beginner  

Example 2 (Intermediate):  
- User: &quot;Python is a high-level language with dynamic typing and supports object-oriented programming.&quot;  
- AI Evaluation: Intermediate  

Example 3 (Advanced):  
- User: &quot;Python manages memory using garbage collection and reference counting, and it supports metaprogramming and asynchronous operations.&quot;  
- AI Evaluation: Advanced  

Now, evaluate the following user response.  
[User response: &ldquo;Python is an interpreter-based language that supports automatic memory management.&rdquo;]  </pre>
</div></div><p /><h2 id="PromptEngineeringforUserLearningLevelAssessmentMethod-3.ImportanceoftheSequenceinPromptEngineeringTechniques">3. <strong>Importance of the Sequence in Prompt Engineering Techniques</strong></h2><p>The order in which prompt engineering techniques are applied plays a crucial role in maximizing the accuracy and consistency of AI evaluations. Each technique complements the others and contributes to progressively improving the reliability and consistency of the evaluation process.</p><ol start="1"><li><p><strong>Self-Consistency Prompting</strong></p><ul><li><p>The AI evaluates the same answer multiple times and selects the most consistent result. This helps to ensure evaluation stability and prevents the problem of varying results from the AI.</p></li></ul></li><li><p><strong>Chain-of-Thought (CoT) Prompting</strong></p><ul><li><p>After consistent evaluations, the AI is prompted to analyze the answer step by step based on logical reasoning. This provides an accurate evaluation rationale and enhances trustworthiness.</p></li></ul></li><li><p><strong>Few-Shot Prompting</strong></p><ul><li><p>AI is provided with level-based examples to reference when evaluating. After establishing consistent evaluation criteria with the previous two steps, the AI uses these examples to make a precise final assessment.</p></li></ul></li></ol><p />
                    </div>

                                        <div class="pageSection group">
                        <div class="pageSectionHeader">
                            <h2 id="attachments" class="pageSectionTitle">Attachments:</h2>
                        </div>

                        <div class="greybox" align="left">
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/1632534531/1632993285.png">image-20250218-194351.png</a> (image/png)
                                <br/>
                                                    </div>
                    </div>
                    
                                                      
                </div>             </div> 
            <div id="footer" role="contentinfo">
                <section class="footer-body">
                    <p>Document generated by Confluence on May 16, 2025 14:27</p>
                    <div id="footer-logo"><a href="http://www.atlassian.com/">Atlassian</a></div>
                </section>
            </div>
        </div>     </body>
</html>
